{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Twitter US Airline Sentiment\n",
    "    \n",
    "### Alfredo Coviello\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the libraries, load dataset, print shape of data, data description. (5 Marks)\n",
    "\n",
    "2. Understand of data-columns: (5 Marks)\n",
    "\n",
    "a. Drop all other columns except “text” and “airline_sentiment”.\n",
    "\n",
    "b. Check the shape of data.\n",
    "\n",
    "c. Print first 5 rows of data.\n",
    "\n",
    "3. Text pre-processing: Data preparation. (20 Marks)\n",
    "\n",
    "a. Html tag removal.\n",
    "\n",
    "b. Tokenization.\n",
    "\n",
    "c. Remove the numbers.\n",
    "\n",
    "d. Removal of Special Characters and Punctuations.\n",
    "\n",
    "e. Conversion to lowercase.\n",
    "\n",
    "f. Lemmatize or stemming.\n",
    "\n",
    "g. Join the words in the list to convert back to text string in the dataframe. (So that each row contains the data in text format.)\n",
    "\n",
    "h. Print first 5 rows of data after pre-processing.\n",
    "\n",
    "4. Vectorization: (10 Marks)\n",
    "\n",
    "a. Use CountVectorizer.\n",
    "\n",
    "b. Use TfidfVectorizer.\n",
    "\n",
    "5. Fit and evaluate model using both type of vectorization. (6+6 Marks)\n",
    "\n",
    "6. Summarize your understanding of the application of Various Pre-processing and Vectorization and performance of your model on this dataset. (8 Marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/acovi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/acovi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/acovi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: contractions in /Users/acovi/Training/MachineLearningFoundations/venv2/lib/python3.7/site-packages (0.0.25)\n",
      "Requirement already satisfied: textsearch in /Users/acovi/Training/MachineLearningFoundations/venv2/lib/python3.7/site-packages (from contractions) (0.0.17)\n",
      "Requirement already satisfied: pyahocorasick in /Users/acovi/Training/MachineLearningFoundations/venv2/lib/python3.7/site-packages (from textsearch->contractions) (1.4.0)\n",
      "Requirement already satisfied: Unidecode in /Users/acovi/Training/MachineLearningFoundations/venv2/lib/python3.7/site-packages (from textsearch->contractions) (1.1.1)\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries.\n",
    "import re, string, unicodedata\n",
    "import pandas as pd\n",
    "import nltk           \n",
    "                        # Natural language processing tool-kit\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "!pip install contractions\n",
    "import contractions\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup                 # Beautiful soup is a parsing library that can use different parsers.\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords, wordnet    # Stopwords, and wordnet corpus\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "tweets = pd.read_csv(\"Tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials to the experience... tacky.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I need to take another trip!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp;amp; they have little recourse</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing about it</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14635</th>\n",
       "      <td>569587686496825344</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3487</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KristenReenders</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir thank you we got on a different flight to Chicago.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 12:01:01 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14636</th>\n",
       "      <td>569587371693355008</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Customer Service Issue</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>itsropes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir leaving over 20 minutes Late Flight. No warnings or communication until we were 15 minutes Late Flight. That's called shitty customer svc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 11:59:46 -0800</td>\n",
       "      <td>Texas</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14637</th>\n",
       "      <td>569587242672398336</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sanyabun</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir Please bring American Airlines to #BlackBerry10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 11:59:15 -0800</td>\n",
       "      <td>Nigeria,lagos</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14638</th>\n",
       "      <td>569587188687634433</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Customer Service Issue</td>\n",
       "      <td>0.6659</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SraJackson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir you have my money, you change my flight, and don't answer your phones! Any other suggestions so I can make my commitment??</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 11:59:02 -0800</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14639</th>\n",
       "      <td>569587140490866689</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6771</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>daviddtwu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir we have 8 ppl so we need 2 know how many seats are on the next flight. Plz put us on standby for 4 people on the next flight?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 11:58:51 -0800</td>\n",
       "      <td>dallas, TX</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14640 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0      570306133677760513           neutral                        1.0000   \n",
       "1      570301130888122368          positive                        0.3486   \n",
       "2      570301083672813571           neutral                        0.6837   \n",
       "3      570301031407624196          negative                        1.0000   \n",
       "4      570300817074462722          negative                        1.0000   \n",
       "...                   ...               ...                           ...   \n",
       "14635  569587686496825344          positive                        0.3487   \n",
       "14636  569587371693355008          negative                        1.0000   \n",
       "14637  569587242672398336           neutral                        1.0000   \n",
       "14638  569587188687634433          negative                        1.0000   \n",
       "14639  569587140490866689           neutral                        0.6771   \n",
       "\n",
       "               negativereason  negativereason_confidence         airline  \\\n",
       "0                         NaN                        NaN  Virgin America   \n",
       "1                         NaN                     0.0000  Virgin America   \n",
       "2                         NaN                        NaN  Virgin America   \n",
       "3                  Bad Flight                     0.7033  Virgin America   \n",
       "4                  Can't Tell                     1.0000  Virgin America   \n",
       "...                       ...                        ...             ...   \n",
       "14635                     NaN                     0.0000        American   \n",
       "14636  Customer Service Issue                     1.0000        American   \n",
       "14637                     NaN                        NaN        American   \n",
       "14638  Customer Service Issue                     0.6659        American   \n",
       "14639                     NaN                     0.0000        American   \n",
       "\n",
       "      airline_sentiment_gold             name negativereason_gold  \\\n",
       "0                        NaN          cairdin                 NaN   \n",
       "1                        NaN         jnardino                 NaN   \n",
       "2                        NaN       yvonnalynn                 NaN   \n",
       "3                        NaN         jnardino                 NaN   \n",
       "4                        NaN         jnardino                 NaN   \n",
       "...                      ...              ...                 ...   \n",
       "14635                    NaN  KristenReenders                 NaN   \n",
       "14636                    NaN         itsropes                 NaN   \n",
       "14637                    NaN         sanyabun                 NaN   \n",
       "14638                    NaN       SraJackson                 NaN   \n",
       "14639                    NaN        daviddtwu                 NaN   \n",
       "\n",
       "       retweet_count  \\\n",
       "0                  0   \n",
       "1                  0   \n",
       "2                  0   \n",
       "3                  0   \n",
       "4                  0   \n",
       "...              ...   \n",
       "14635              0   \n",
       "14636              0   \n",
       "14637              0   \n",
       "14638              0   \n",
       "14639              0   \n",
       "\n",
       "                                                                                                                                                         text  \\\n",
       "0                                                                                                                         @VirginAmerica What @dhepburn said.   \n",
       "1                                                                                    @VirginAmerica plus you've added commercials to the experience... tacky.   \n",
       "2                                                                                     @VirginAmerica I didn't today... Must mean I need to take another trip!   \n",
       "3                              @VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp; they have little recourse   \n",
       "4                                                                                                     @VirginAmerica and it's a really big bad thing about it   \n",
       "...                                                                                                                                                       ...   \n",
       "14635                                                                                         @AmericanAir thank you we got on a different flight to Chicago.   \n",
       "14636  @AmericanAir leaving over 20 minutes Late Flight. No warnings or communication until we were 15 minutes Late Flight. That's called shitty customer svc   \n",
       "14637                                                                                            @AmericanAir Please bring American Airlines to #BlackBerry10   \n",
       "14638                 @AmericanAir you have my money, you change my flight, and don't answer your phones! Any other suggestions so I can make my commitment??   \n",
       "14639              @AmericanAir we have 8 ppl so we need 2 know how many seats are on the next flight. Plz put us on standby for 4 people on the next flight?   \n",
       "\n",
       "      tweet_coord              tweet_created tweet_location  \\\n",
       "0             NaN  2015-02-24 11:35:52 -0800            NaN   \n",
       "1             NaN  2015-02-24 11:15:59 -0800            NaN   \n",
       "2             NaN  2015-02-24 11:15:48 -0800      Lets Play   \n",
       "3             NaN  2015-02-24 11:15:36 -0800            NaN   \n",
       "4             NaN  2015-02-24 11:14:45 -0800            NaN   \n",
       "...           ...                        ...            ...   \n",
       "14635         NaN  2015-02-22 12:01:01 -0800            NaN   \n",
       "14636         NaN  2015-02-22 11:59:46 -0800          Texas   \n",
       "14637         NaN  2015-02-22 11:59:15 -0800  Nigeria,lagos   \n",
       "14638         NaN  2015-02-22 11:59:02 -0800     New Jersey   \n",
       "14639         NaN  2015-02-22 11:58:51 -0800     dallas, TX   \n",
       "\n",
       "                    user_timezone  \n",
       "0      Eastern Time (US & Canada)  \n",
       "1      Pacific Time (US & Canada)  \n",
       "2      Central Time (US & Canada)  \n",
       "3      Pacific Time (US & Canada)  \n",
       "4      Pacific Time (US & Canada)  \n",
       "...                           ...  \n",
       "14635                         NaN  \n",
       "14636                         NaN  \n",
       "14637                         NaN  \n",
       "14638  Eastern Time (US & Canada)  \n",
       "14639                         NaN  \n",
       "\n",
       "[14640 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14640, 15)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>retweet_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.464000e+04</td>\n",
       "      <td>14640.000000</td>\n",
       "      <td>10522.000000</td>\n",
       "      <td>14640.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.692184e+17</td>\n",
       "      <td>0.900169</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.082650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.791112e+14</td>\n",
       "      <td>0.162830</td>\n",
       "      <td>0.330440</td>\n",
       "      <td>0.745778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.675883e+17</td>\n",
       "      <td>0.335000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.685592e+17</td>\n",
       "      <td>0.692300</td>\n",
       "      <td>0.360600</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.694779e+17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.670600</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.698905e+17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.703106e+17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>44.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           tweet_id  airline_sentiment_confidence  negativereason_confidence  \\\n",
       "count  1.464000e+04                  14640.000000               10522.000000   \n",
       "mean   5.692184e+17                      0.900169                   0.638298   \n",
       "std    7.791112e+14                      0.162830                   0.330440   \n",
       "min    5.675883e+17                      0.335000                   0.000000   \n",
       "25%    5.685592e+17                      0.692300                   0.360600   \n",
       "50%    5.694779e+17                      1.000000                   0.670600   \n",
       "75%    5.698905e+17                      1.000000                   1.000000   \n",
       "max    5.703106e+17                      1.000000                   1.000000   \n",
       "\n",
       "       retweet_count  \n",
       "count   14640.000000  \n",
       "mean        0.082650  \n",
       "std         0.745778  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max        44.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14640 entries, 0 to 14639\n",
      "Data columns (total 15 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   tweet_id                      14640 non-null  int64  \n",
      " 1   airline_sentiment             14640 non-null  object \n",
      " 2   airline_sentiment_confidence  14640 non-null  float64\n",
      " 3   negativereason                9178 non-null   object \n",
      " 4   negativereason_confidence     10522 non-null  float64\n",
      " 5   airline                       14640 non-null  object \n",
      " 6   airline_sentiment_gold        40 non-null     object \n",
      " 7   name                          14640 non-null  object \n",
      " 8   negativereason_gold           32 non-null     object \n",
      " 9   retweet_count                 14640 non-null  int64  \n",
      " 10  text                          14640 non-null  object \n",
      " 11  tweet_coord                   1019 non-null   object \n",
      " 12  tweet_created                 14640 non-null  object \n",
      " 13  tweet_location                9907 non-null   object \n",
      " 14  user_timezone                 9820 non-null   object \n",
      "dtypes: float64(2), int64(2), object(11)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets[['text', 'airline_sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica plus you've added commercials to the experience... tacky.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I need to take another trip!</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp;amp; they have little recourse</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing about it</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                             text  \\\n",
       "0                                                                                             @VirginAmerica What @dhepburn said.   \n",
       "1                                                        @VirginAmerica plus you've added commercials to the experience... tacky.   \n",
       "2                                                         @VirginAmerica I didn't today... Must mean I need to take another trip!   \n",
       "3  @VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp; they have little recourse   \n",
       "4                                                                         @VirginAmerica and it's a really big bad thing about it   \n",
       "\n",
       "  airline_sentiment  \n",
       "0           neutral  \n",
       "1          positive  \n",
       "2           neutral  \n",
       "3          negative  \n",
       "4          negative  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14640, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    9178\n",
       "neutral     3099\n",
       "positive    2363\n",
       "Name: airline_sentiment, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.airline_sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Pre-processing\n",
    "\n",
    "a. Html tag removal.\n",
    "\n",
    "b. Tokenization.\n",
    "\n",
    "c. Remove the numbers.\n",
    "\n",
    "d. Removal of Special Characters and Punctuations.\n",
    "\n",
    "e. Conversion to lowercase.\n",
    "\n",
    "f. Lemmatize or stemming.\n",
    "\n",
    "g. Join the words in the list to convert back to text string in the dataframe. (So that each row contains the data in text format.)\n",
    "\n",
    "h. Print first 5 rows of data after pre-processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/acovi/Training/MachineLearningFoundations/venv2/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# HTML tag removal\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def remove_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    pure_text = soup.get_text()\n",
    "    return pure_text\n",
    "\n",
    "tweets['text'] = tweets[\"text\"].apply(lambda x: remove_html(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica plus you've added commercials to the experience... tacky.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I need to take another trip!</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp; they have little recourse</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing about it</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14635</th>\n",
       "      <td>@AmericanAir thank you we got on a different flight to Chicago.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14636</th>\n",
       "      <td>@AmericanAir leaving over 20 minutes Late Flight. No warnings or communication until we were 15 minutes Late Flight. That's called shitty customer svc</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14637</th>\n",
       "      <td>@AmericanAir Please bring American Airlines to #BlackBerry10</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14638</th>\n",
       "      <td>@AmericanAir you have my money, you change my flight, and don't answer your phones! Any other suggestions so I can make my commitment??</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14639</th>\n",
       "      <td>@AmericanAir we have 8 ppl so we need 2 know how many seats are on the next flight. Plz put us on standby for 4 people on the next flight?</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14640 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                         text  \\\n",
       "0                                                                                                                         @VirginAmerica What @dhepburn said.   \n",
       "1                                                                                    @VirginAmerica plus you've added commercials to the experience... tacky.   \n",
       "2                                                                                     @VirginAmerica I didn't today... Must mean I need to take another trip!   \n",
       "3                                  @VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces & they have little recourse   \n",
       "4                                                                                                     @VirginAmerica and it's a really big bad thing about it   \n",
       "...                                                                                                                                                       ...   \n",
       "14635                                                                                         @AmericanAir thank you we got on a different flight to Chicago.   \n",
       "14636  @AmericanAir leaving over 20 minutes Late Flight. No warnings or communication until we were 15 minutes Late Flight. That's called shitty customer svc   \n",
       "14637                                                                                            @AmericanAir Please bring American Airlines to #BlackBerry10   \n",
       "14638                 @AmericanAir you have my money, you change my flight, and don't answer your phones! Any other suggestions so I can make my commitment??   \n",
       "14639              @AmericanAir we have 8 ppl so we need 2 know how many seats are on the next flight. Plz put us on standby for 4 people on the next flight?   \n",
       "\n",
       "      airline_sentiment  \n",
       "0               neutral  \n",
       "1              positive  \n",
       "2               neutral  \n",
       "3              negative  \n",
       "4              negative  \n",
       "...                 ...  \n",
       "14635          positive  \n",
       "14636          negative  \n",
       "14637           neutral  \n",
       "14638          negative  \n",
       "14639           neutral  \n",
       "\n",
       "[14640 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/acovi/Training/MachineLearningFoundations/venv2/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[@, VirginAmerica, What, @, dhepburn, said, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica plus you've added commercials to the experience... tacky.</td>\n",
       "      <td>positive</td>\n",
       "      <td>[@, VirginAmerica, plus, you, 've, added, commercials, to, the, experience, ..., tacky, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I need to take another trip!</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[@, VirginAmerica, I, did, n't, today, ..., Must, mean, I, need, to, take, another, trip, !]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp; they have little recourse</td>\n",
       "      <td>negative</td>\n",
       "      <td>[@, VirginAmerica, it, 's, really, aggressive, to, blast, obnoxious, ``, entertainment, '', in, your, guests, ', faces, &amp;, they, have, little, recourse]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing about it</td>\n",
       "      <td>negative</td>\n",
       "      <td>[@, VirginAmerica, and, it, 's, a, really, big, bad, thing, about, it]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14635</th>\n",
       "      <td>@AmericanAir thank you we got on a different flight to Chicago.</td>\n",
       "      <td>positive</td>\n",
       "      <td>[@, AmericanAir, thank, you, we, got, on, a, different, flight, to, Chicago, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14636</th>\n",
       "      <td>@AmericanAir leaving over 20 minutes Late Flight. No warnings or communication until we were 15 minutes Late Flight. That's called shitty customer svc</td>\n",
       "      <td>negative</td>\n",
       "      <td>[@, AmericanAir, leaving, over, 20, minutes, Late, Flight, ., No, warnings, or, communication, until, we, were, 15, minutes, Late, Flight, ., That, 's, called, shitty, customer, svc]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14637</th>\n",
       "      <td>@AmericanAir Please bring American Airlines to #BlackBerry10</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[@, AmericanAir, Please, bring, American, Airlines, to, #, BlackBerry10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14638</th>\n",
       "      <td>@AmericanAir you have my money, you change my flight, and don't answer your phones! Any other suggestions so I can make my commitment??</td>\n",
       "      <td>negative</td>\n",
       "      <td>[@, AmericanAir, you, have, my, money, ,, you, change, my, flight, ,, and, do, n't, answer, your, phones, !, Any, other, suggestions, so, I, can, make, my, commitment, ?, ?]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14639</th>\n",
       "      <td>@AmericanAir we have 8 ppl so we need 2 know how many seats are on the next flight. Plz put us on standby for 4 people on the next flight?</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[@, AmericanAir, we, have, 8, ppl, so, we, need, 2, know, how, many, seats, are, on, the, next, flight, ., Plz, put, us, on, standby, for, 4, people, on, the, next, flight, ?]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14640 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                         text  \\\n",
       "0                                                                                                                         @VirginAmerica What @dhepburn said.   \n",
       "1                                                                                    @VirginAmerica plus you've added commercials to the experience... tacky.   \n",
       "2                                                                                     @VirginAmerica I didn't today... Must mean I need to take another trip!   \n",
       "3                                  @VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces & they have little recourse   \n",
       "4                                                                                                     @VirginAmerica and it's a really big bad thing about it   \n",
       "...                                                                                                                                                       ...   \n",
       "14635                                                                                         @AmericanAir thank you we got on a different flight to Chicago.   \n",
       "14636  @AmericanAir leaving over 20 minutes Late Flight. No warnings or communication until we were 15 minutes Late Flight. That's called shitty customer svc   \n",
       "14637                                                                                            @AmericanAir Please bring American Airlines to #BlackBerry10   \n",
       "14638                 @AmericanAir you have my money, you change my flight, and don't answer your phones! Any other suggestions so I can make my commitment??   \n",
       "14639              @AmericanAir we have 8 ppl so we need 2 know how many seats are on the next flight. Plz put us on standby for 4 people on the next flight?   \n",
       "\n",
       "      airline_sentiment  \\\n",
       "0               neutral   \n",
       "1              positive   \n",
       "2               neutral   \n",
       "3              negative   \n",
       "4              negative   \n",
       "...                 ...   \n",
       "14635          positive   \n",
       "14636          negative   \n",
       "14637           neutral   \n",
       "14638          negative   \n",
       "14639           neutral   \n",
       "\n",
       "                                                                                                                                                                                       tokens  \n",
       "0                                                                                                                                              [@, VirginAmerica, What, @, dhepburn, said, .]  \n",
       "1                                                                                                  [@, VirginAmerica, plus, you, 've, added, commercials, to, the, experience, ..., tacky, .]  \n",
       "2                                                                                                [@, VirginAmerica, I, did, n't, today, ..., Must, mean, I, need, to, take, another, trip, !]  \n",
       "3                                    [@, VirginAmerica, it, 's, really, aggressive, to, blast, obnoxious, ``, entertainment, '', in, your, guests, ', faces, &, they, have, little, recourse]  \n",
       "4                                                                                                                      [@, VirginAmerica, and, it, 's, a, really, big, bad, thing, about, it]  \n",
       "...                                                                                                                                                                                       ...  \n",
       "14635                                                                                                         [@, AmericanAir, thank, you, we, got, on, a, different, flight, to, Chicago, .]  \n",
       "14636  [@, AmericanAir, leaving, over, 20, minutes, Late, Flight, ., No, warnings, or, communication, until, we, were, 15, minutes, Late, Flight, ., That, 's, called, shitty, customer, svc]  \n",
       "14637                                                                                                                [@, AmericanAir, Please, bring, American, Airlines, to, #, BlackBerry10]  \n",
       "14638           [@, AmericanAir, you, have, my, money, ,, you, change, my, flight, ,, and, do, n't, answer, your, phones, !, Any, other, suggestions, so, I, can, make, my, commitment, ?, ?]  \n",
       "14639         [@, AmericanAir, we, have, 8, ppl, so, we, need, 2, know, how, many, seats, are, on, the, next, flight, ., Plz, put, us, on, standby, for, 4, people, on, the, next, flight, ?]  \n",
       "\n",
       "[14640 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenization\n",
    "\n",
    "tweets['tokens'] = tweets['text'].apply(lambda x: nltk.word_tokenize(x))\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[@, VirginAmerica, What, @, dhepburn, said, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica plus you've added commercials to the experience... tacky.</td>\n",
       "      <td>positive</td>\n",
       "      <td>[@, VirginAmerica, plus, you, 've, added, commercials, to, the, experience, ..., tacky, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I need to take another trip!</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[@, VirginAmerica, I, did, n't, today, ..., Must, mean, I, need, to, take, another, trip, !]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp; they have little recourse</td>\n",
       "      <td>negative</td>\n",
       "      <td>[@, VirginAmerica, it, 's, really, aggressive, to, blast, obnoxious, ``, entertainment, '', in, your, guests, ', faces, &amp;, they, have, little, recourse]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing about it</td>\n",
       "      <td>negative</td>\n",
       "      <td>[@, VirginAmerica, and, it, 's, a, really, big, bad, thing, about, it]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14635</th>\n",
       "      <td>@AmericanAir thank you we got on a different flight to Chicago.</td>\n",
       "      <td>positive</td>\n",
       "      <td>[@, AmericanAir, thank, you, we, got, on, a, different, flight, to, Chicago, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14636</th>\n",
       "      <td>@AmericanAir leaving over 20 minutes Late Flight. No warnings or communication until we were 15 minutes Late Flight. That's called shitty customer svc</td>\n",
       "      <td>negative</td>\n",
       "      <td>[@, AmericanAir, leaving, over, 20, minutes, Late, Flight, ., No, warnings, or, communication, until, we, were, 15, minutes, Late, Flight, ., That, 's, called, shitty, customer, svc]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14637</th>\n",
       "      <td>@AmericanAir Please bring American Airlines to #BlackBerry10</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[@, AmericanAir, Please, bring, American, Airlines, to, #, BlackBerry10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14638</th>\n",
       "      <td>@AmericanAir you have my money, you change my flight, and don't answer your phones! Any other suggestions so I can make my commitment??</td>\n",
       "      <td>negative</td>\n",
       "      <td>[@, AmericanAir, you, have, my, money, ,, you, change, my, flight, ,, and, do, n't, answer, your, phones, !, Any, other, suggestions, so, I, can, make, my, commitment, ?, ?]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14639</th>\n",
       "      <td>@AmericanAir we have 8 ppl so we need 2 know how many seats are on the next flight. Plz put us on standby for 4 people on the next flight?</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[@, AmericanAir, we, have, 8, ppl, so, we, need, 2, know, how, many, seats, are, on, the, next, flight, ., Plz, put, us, on, standby, for, 4, people, on, the, next, flight, ?]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14640 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                         text  \\\n",
       "0                                                                                                                         @VirginAmerica What @dhepburn said.   \n",
       "1                                                                                    @VirginAmerica plus you've added commercials to the experience... tacky.   \n",
       "2                                                                                     @VirginAmerica I didn't today... Must mean I need to take another trip!   \n",
       "3                                  @VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces & they have little recourse   \n",
       "4                                                                                                     @VirginAmerica and it's a really big bad thing about it   \n",
       "...                                                                                                                                                       ...   \n",
       "14635                                                                                         @AmericanAir thank you we got on a different flight to Chicago.   \n",
       "14636  @AmericanAir leaving over 20 minutes Late Flight. No warnings or communication until we were 15 minutes Late Flight. That's called shitty customer svc   \n",
       "14637                                                                                            @AmericanAir Please bring American Airlines to #BlackBerry10   \n",
       "14638                 @AmericanAir you have my money, you change my flight, and don't answer your phones! Any other suggestions so I can make my commitment??   \n",
       "14639              @AmericanAir we have 8 ppl so we need 2 know how many seats are on the next flight. Plz put us on standby for 4 people on the next flight?   \n",
       "\n",
       "      airline_sentiment  \\\n",
       "0               neutral   \n",
       "1              positive   \n",
       "2               neutral   \n",
       "3              negative   \n",
       "4              negative   \n",
       "...                 ...   \n",
       "14635          positive   \n",
       "14636          negative   \n",
       "14637           neutral   \n",
       "14638          negative   \n",
       "14639           neutral   \n",
       "\n",
       "                                                                                                                                                                                       tokens  \n",
       "0                                                                                                                                              [@, VirginAmerica, What, @, dhepburn, said, .]  \n",
       "1                                                                                                  [@, VirginAmerica, plus, you, 've, added, commercials, to, the, experience, ..., tacky, .]  \n",
       "2                                                                                                [@, VirginAmerica, I, did, n't, today, ..., Must, mean, I, need, to, take, another, trip, !]  \n",
       "3                                    [@, VirginAmerica, it, 's, really, aggressive, to, blast, obnoxious, ``, entertainment, '', in, your, guests, ', faces, &, they, have, little, recourse]  \n",
       "4                                                                                                                      [@, VirginAmerica, and, it, 's, a, really, big, bad, thing, about, it]  \n",
       "...                                                                                                                                                                                       ...  \n",
       "14635                                                                                                         [@, AmericanAir, thank, you, we, got, on, a, different, flight, to, Chicago, .]  \n",
       "14636  [@, AmericanAir, leaving, over, 20, minutes, Late, Flight, ., No, warnings, or, communication, until, we, were, 15, minutes, Late, Flight, ., That, 's, called, shitty, customer, svc]  \n",
       "14637                                                                                                                [@, AmericanAir, Please, bring, American, Airlines, to, #, BlackBerry10]  \n",
       "14638           [@, AmericanAir, you, have, my, money, ,, you, change, my, flight, ,, and, do, n't, answer, your, phones, !, Any, other, suggestions, so, I, can, make, my, commitment, ?, ?]  \n",
       "14639         [@, AmericanAir, we, have, 8, ppl, so, we, need, 2, know, how, many, seats, are, on, the, next, flight, ., Plz, put, us, on, standby, for, 4, people, on, the, next, flight, ?]  \n",
       "\n",
       "[14640 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/acovi/Training/MachineLearningFoundations/venv2/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# Remove numbers and special characters and punctation, and convert to lowercase\n",
    "\n",
    "def remove_numbers_and_special_chars(list_text):\n",
    "    pattern = r'[^a-zA-Z]'\n",
    "    word_list = []\n",
    "    for t in list_text:\n",
    "        text = re.sub(pattern, '', t)\n",
    "        word_list.append(text.lower())\n",
    "    return word_list\n",
    "\n",
    "tweets['no_numbers'] = tweets[\"tokens\"].apply(lambda x: remove_numbers_and_special_chars(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                                                                                           [, virginamerica, what, , dhepburn, said, ]\n",
       "1                                                                                                  [, virginamerica, plus, you, ve, added, commercials, to, the, experience, , tacky, ]\n",
       "2                                                                                                [, virginamerica, i, did, nt, today, , must, mean, i, need, to, take, another, trip, ]\n",
       "3                                      [, virginamerica, it, s, really, aggressive, to, blast, obnoxious, , entertainment, , in, your, guests, , faces, , they, have, little, recourse]\n",
       "4                                                                                                                  [, virginamerica, and, it, s, a, really, big, bad, thing, about, it]\n",
       "                                                                                              ...                                                                                      \n",
       "14635                                                                                                     [, americanair, thank, you, we, got, on, a, different, flight, to, chicago, ]\n",
       "14636    [, americanair, leaving, over, , minutes, late, flight, , no, warnings, or, communication, until, we, were, , minutes, late, flight, , that, s, called, shitty, customer, svc]\n",
       "14637                                                                                                              [, americanair, please, bring, american, airlines, to, , blackberry]\n",
       "14638            [, americanair, you, have, my, money, , you, change, my, flight, , and, do, nt, answer, your, phones, , any, other, suggestions, so, i, can, make, my, commitment, , ]\n",
       "14639         [, americanair, we, have, , ppl, so, we, need, , know, how, many, seats, are, on, the, next, flight, , plz, put, us, on, standby, for, , people, on, the, next, flight, ]\n",
       "Name: no_numbers, Length: 14640, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['no_numbers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/acovi/Training/MachineLearningFoundations/venv2/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# Lemmatize / stemming\n",
    "\n",
    "def stem_words(words):\n",
    "    stemmer = LancasterStemmer()\n",
    "    stems = []\n",
    "    for word in words:\n",
    "        stem = stemmer.stem(word)\n",
    "        stems.append(stem)\n",
    "    return stems\n",
    "\n",
    "tweets['stems'] = tweets['no_numbers'].apply(lambda x: stem_words(x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                                                                                  [, virginameric, what, , dhepburn, said, ]\n",
       "1                                                                                                     [, virginameric, plu, you, ve, ad, commerc, to, the, expery, , tacky, ]\n",
       "2                                                                                           [, virginameric, i, did, nt, today, , must, mean, i, nee, to, tak, anoth, trip, ]\n",
       "3                                                 [, virginameric, it, s, real, aggress, to, blast, obnoxy, , entertain, , in, yo, guest, , fac, , they, hav, littl, recours]\n",
       "4                                                                                                           [, virginameric, and, it, s, a, real, big, bad, thing, about, it]\n",
       "                                                                                         ...                                                                                 \n",
       "14635                                                                                                [, americanair, thank, you, we, got, on, a, diff, flight, to, chicago, ]\n",
       "14636                      [, americanair, leav, ov, , minut, lat, flight, , no, warn, or, commun, until, we, wer, , minut, lat, flight, , that, s, cal, shitty, custom, svc]\n",
       "14637                                                                                                             [, americanair, pleas, bring, am, airlin, to, , blackberry]\n",
       "14638                     [, americanair, you, hav, my, money, , you, chang, my, flight, , and, do, nt, answ, yo, phon, , any, oth, suggest, so, i, can, mak, my, commit, , ]\n",
       "14639    [, americanair, we, hav, , ppl, so, we, nee, , know, how, many, seat, ar, on, the, next, flight, , plz, put, us, on, standby, for, , peopl, on, the, next, flight, ]\n",
       "Name: stems, Length: 14640, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/acovi/Training/MachineLearningFoundations/venv2/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "def lemmatize(words):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = []\n",
    "    for word in words:\n",
    "        lemma = lemmatizer.lemmatize(word)\n",
    "        lemmas.append(lemma)\n",
    "    return lemmas\n",
    "\n",
    "tweets['lemas'] = tweets['no_numbers'].apply(lambda x: lemmatize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                                                                                        [, virginamerica, what, , dhepburn, said, ]\n",
       "1                                                                                                [, virginamerica, plus, you, ve, added, commercial, to, the, experience, , tacky, ]\n",
       "2                                                                                             [, virginamerica, i, did, nt, today, , must, mean, i, need, to, take, another, trip, ]\n",
       "3                                     [, virginamerica, it, s, really, aggressive, to, blast, obnoxious, , entertainment, , in, your, guest, , face, , they, have, little, recourse]\n",
       "4                                                                                                               [, virginamerica, and, it, s, a, really, big, bad, thing, about, it]\n",
       "                                                                                            ...                                                                                     \n",
       "14635                                                                                                  [, americanair, thank, you, we, got, on, a, different, flight, to, chicago, ]\n",
       "14636    [, americanair, leaving, over, , minute, late, flight, , no, warning, or, communication, until, we, were, , minute, late, flight, , that, s, called, shitty, customer, svc]\n",
       "14637                                                                                                            [, americanair, please, bring, american, airline, to, , blackberry]\n",
       "14638           [, americanair, you, have, my, money, , you, change, my, flight, , and, do, nt, answer, your, phone, , any, other, suggestion, so, i, can, make, my, commitment, , ]\n",
       "14639        [, americanair, we, have, , ppl, so, we, need, , know, how, many, seat, are, on, the, next, flight, , plz, put, u, on, standby, for, , people, on, the, next, flight, ]\n",
       "Name: lemas, Length: 14640, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.lemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/acovi/Training/MachineLearningFoundations/venv2/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/acovi/Training/MachineLearningFoundations/venv2/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "tweets['lemas_one'] = tweets['lemas'].apply(lambda x: ' '.join(x))\n",
    "tweets['stems_one'] = tweets['stems'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                                         virginamerica what  dhepburn said \n",
       "1                                                       virginamerica plus you ve added commercial to the experience  tacky \n",
       "2                                                       virginamerica i did nt today  must mean i need to take another trip \n",
       "3     virginamerica it s really aggressive to blast obnoxious  entertainment  in your guest  face  they have little recourse\n",
       "4                                                                     virginamerica and it s a really big bad thing about it\n",
       "Name: lemas_one, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.lemas_one.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                       virginameric what  dhepburn said \n",
       "1                                                virginameric plu you ve ad commerc to the expery  tacky \n",
       "2                                         virginameric i did nt today  must mean i nee to tak anoth trip \n",
       "3     virginameric it s real aggress to blast obnoxy  entertain  in yo guest  fac  they hav littl recours\n",
       "4                                                     virginameric and it s a real big bad thing about it\n",
       "Name: stems_one, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.stems_one.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14640 entries, 0 to 14639\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   text               14640 non-null  object\n",
      " 1   airline_sentiment  14640 non-null  object\n",
      " 2   tokens             14640 non-null  object\n",
      " 3   no_numbers         14640 non-null  object\n",
      " 4   stems              14640 non-null  object\n",
      " 5   lemas              14640 non-null  object\n",
      " 6   lemas_one          14640 non-null  object\n",
      " 7   stems_one          14640 non-null  object\n",
      "dtypes: object(8)\n",
      "memory usage: 915.1+ KB\n"
     ]
    }
   ],
   "source": [
    "tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=5000)\n",
    "vec_stems_data_features = vectorizer.fit_transform(tweets['stems_one'])\n",
    "vec_stems_data_features = vec_stems_data_features.toarray()\n",
    "\n",
    "vec_lemas_data_features = vectorizer.fit_transform(tweets['lemas_one'])\n",
    "vec_lemas_data_features = vec_lemas_data_features.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14640, 5000)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_stems_data_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14640, 5000)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_lemas_data_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_stems_data_featuress_data_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and evaluate the model\n",
    "# Model 1: stemming countvectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "labels = tweets['airline_sentiment']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(vec_stems_data_features,labels, test_size=0.3, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10248, 5000)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4392, 5000)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10248,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4392,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stemming countvectorizer\n",
      "RandomForestClassifier(n_estimators=50, n_jobs=4)\n",
      "0.7379781420765028\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=50, n_jobs=4)\n",
    "\n",
    "forest = forest.fit(X_train, y_train)\n",
    "\n",
    "print(\"stemming countvectorizer\")\n",
    "print(forest)\n",
    "\n",
    "print(np.mean(cross_val_score(forest, vec_stems_data_features, labels, cv=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemmatizer countvectorizer\n",
      "RandomForestClassifier(n_estimators=50, n_jobs=4)\n",
      "0.735860655737705\n"
     ]
    }
   ],
   "source": [
    "# Model 2: lemmatizer countvectorizer\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(vec_lemas_data_features,labels, test_size=0.3, random_state=7)\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=50, n_jobs=4)\n",
    "\n",
    "forest = forest.fit(X_train, y_train)\n",
    "\n",
    "print(\"lemmatizer countvectorizer\")\n",
    "print(forest)\n",
    "\n",
    "print(np.mean(cross_val_score(forest, vec_lemas_data_features, labels, cv=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "tfidf_stems_data_features = vectorizer.fit_transform(tweets['stems_one'])\n",
    "tfidf_stems_data_features = tfidf_stems_data_features.toarray()\n",
    "\n",
    "tfidf_lemas_data_features = vectorizer.fit_transform(tweets['lemas_one'])\n",
    "tfidf_lemas_data_features = tfidf_lemas_data_features.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14640, 5000)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_stems_data_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14640, 5000)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_lemas_data_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stemming tfidfvectorizer\n",
      "RandomForestClassifier(n_estimators=50, n_jobs=4)\n",
      "0.7295765027322404\n"
     ]
    }
   ],
   "source": [
    "# Model 3: stemming tfidfvectorizer\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_stems_data_features,labels, test_size=0.3, random_state=7)\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=50, n_jobs=4)\n",
    "\n",
    "forest = forest.fit(X_train, y_train)\n",
    "\n",
    "print(\"stemming tfidfvectorizer\")\n",
    "print(forest)\n",
    "\n",
    "print(np.mean(cross_val_score(forest, tfidf_stems_data_features, labels, cv=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemmatizer tfidfvectorizer\n",
      "RandomForestClassifier(n_estimators=50, n_jobs=4)\n",
      "0.7261612021857923\n"
     ]
    }
   ],
   "source": [
    "# Model 4: lemmatizer tfidfvectorizer\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_lemas_data_features,labels, test_size=0.3, random_state=7)\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=50, n_jobs=4)\n",
    "\n",
    "forest = forest.fit(X_train, y_train)\n",
    "\n",
    "print(\"lemmatizer tfidfvectorizer\")\n",
    "print(forest)\n",
    "\n",
    "print(np.mean(cross_val_score(forest, tfidf_lemas_data_features, labels, cv=10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The corpus is a list of short texts, usually one or a few sentences (tweets).\n",
    "The methods rely in using human language words as features of the texts. For this reason, and to minimize the number of features, a number of pre-processing techniques were applied:\n",
    "- removal of HTML tags\n",
    "- tokenization, or splitting of sentences into words\n",
    "- removal of special character and numbers\n",
    "- conversion to lowercase, so that character case does not create different words\n",
    "\n",
    "Also, lemmatization and stemming were used for the same reason, to reduce the universe of words to common words roots and reduce the number of features.\n",
    "\n",
    "Words need to be converted into numbers, or vectors, which become the features for the classification model.\n",
    "I choose to try both approaches to see how they behaved.\n",
    "Count Vectorizer, or bag of words, simply counts the number of times each word (token) appears.\n",
    "TF IDF Vectorizer, combines the count of times a word appears in the text (more times, more important) and the number of documents of the corpus where it appears (less times, more important = it's less common, more unique and more important as a distinctive feature of the documents where it appears).\n",
    "\n",
    "The 4 models had very similar performances. Vectorization type or stem vs lema \"rooting\" did not show a meaningful difference. This might be due to the short lenght of the documents, i.e. tweets, and the nature of the language, i.e. vocabulary is not too varied.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
